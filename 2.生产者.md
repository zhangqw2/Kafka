## 一、客户端开发

&emsp;&emsp;一个正常的生产逻辑需要具备以下几个步骤:

- 1.配置生产者客户端参数以及创建相应的生产者实例

- 2.构建待发送的消息

- 3.发送消息

- 4.关闭生产者实例

```java
public class ProducerRecord<K,V>{
  /**
   * 主题
   */
  private final String topic;
   /**
    * 分区号
    */
  private final Integer partition;
  /**
   *消息头部
   */
  private final Headers headers;
  /**
   *键
   */
  private final K key;
   /**
    *值
    */
  private final V value;
   /**
    *消息的时间戳
    */
  private final Long timestamp;
  
  //省略其他成员方法和构造方法
}
```

### 1.1 必要的参数配置

&emsp;&emsp;在创建真正的生产者实例前需要配置相应的参数，在Kakfa生产者客户端KafkaProducer中有3个参数是必填的。

- bootstrap.servers: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单，具体内容格式: host1:port1,host2:port2 ,可以设置一个或多个地址，中间以逗号隔开，此参数的默认值为""。注意这里并非需要所有的broker地址，因为生产者会从给定的broker里查找到其他broker的信息。不过建议至少要设置两个以上的broker地址信息，当其中任意一个宕机时，生产者仍然可以连接到Kafka集群上。
- key.serializer 和 value.serializer: broker端接收的消息必须以字节数组的形式存在。生产者客户端在发往broker之前需要将消息中对应的key和value做相应的序列化操作来转换成字节数组。key.serializer 和 value.serializer这两个参数分别用来指定key和value序列化操作的序列化器，这两个参数无默认值,而且必须填写序列化器的全限定名



&emsp;&emsp;还可以指定client.id，如果客户端不设置，则KafaProducer会自动生成一个非空字符串，内容形式如“producer-1”，“producer-2”，即字符串“producer-”与数字的拼接。

&emsp;&emsp;可以使用客户端中的org.apache.kafka.clients.producer.ProducerConfig类来做一定程序上的预防拼错措施，每个参数在ProducerConfig类中都有对应的名称

```java
public static Properties initConfig(){
  Properties props = new Properties();
 props.put(ProducerConfig.BOOT_SERVERS_CONFIG,brokerList);
  props put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG ,"org.apache.kafka.common.serialization.StringSerializer"); 
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,"org.apache.kafka.common.serialization.StringSerializer");
props.put(ProducerConfig.CLIENT_ID_CONFIG,"producer.client.id.demo ") ; 
return props;
}
```

&emsp;&emsp;在配置完参数之后，我们就可以使用它来创建一个生产者实例，示例如下：

```java
KafkaProducer<String,String> producer = new KafkaProducer<>(props);
```

&emsp;&emsp;KafkaProducer是线程安全的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用。

&emsp;&emsp;KafkaProducer 中有多个构造方法，比如在创 KafkaProducer 实例时并没有设定key.serializer 和value.serializer 这两个配置参数，那么就需要在构造方法中添加对应的序列化器，示例如下：

```java
KafkaProducer<String, String> producer= new KafkaProducer<>(props, new StringSerializer() ,new StringSerializer()); 
```



&emsp;&emsp;其内部原理和无序列化器的构造方法 样，不过就实际应用而言，一般都选用 public KafkaProducer(Properties properties）这个构造方法来创建 KafkaProducer 实例。



### 1.2 消息的发送

&emsp;&emsp;在创建完生产者实例之后，接下来的工作就是构建消息，即创建ProducerRecord对象。对应的ProducerRecord的构造方法也有多种，参考如下: 

```java
public ProducerRecord(String topic,Integer partition,Long timestamp,K key,V value,Iterable<Header> headers)
public ProducerRecord(String topic,Integer partition,Long timestamp,K key ,V value)
public ProducerRecord(String topic,Integer partition,K key ,V value,Iterable<Header> headers)
public ProducerRecord(String topic,Integer partition,K key ,V value) 
public ProducerRecord(String topic,K key ,V value) 
public ProducerRecord(String topic,V value)   
```

&emsp;&emsp;创建生产者实例和构建消息之后，就可以开始发送消息了。发送消息主要有三种模式: 发后即忘(fire-and-forget)、同步(sync)及异步(async)。

&emsp;&emsp;KafkaProducer的send()方法并非是void类型，而是Future\<RecordMetadata\>类型，send()方法有2个重载方法，具体定义如下:

```java
public Future<RecordMetadata> send(ProducerRecord<K,V> record)
public Future<RecordMetadata> send(ProducerRecord<K,V> record,Callback callback)
```

&emsp;&emsp;要实现同步的发送方式，可以利用返回的Future对象实现，示例如下:

```java
try{
  producer.send(record).get();
}catch(ExecutionException | InterruptedException e){
  e.printStackTrace();
}
```

&emsp;&emsp;实际上send()方法本身就是异步的，send()方法返回的Future对象可以使调用方稍后获得发送的结果。

&emsp;&emsp;也可以在执行完send()方法之后不直接调用get()方法，比如下面的一种同步发送方式的实现:

```java
try{
  Future<RecordMetadata> future = producer.send(record);
  RecordMetadata metadata = future.get();
  System.out.println(metadata.topic()+ "_"+metadata.partition()+"_"+metadata.offset());
}catch(ExectionException | InterruptedException e){
  e.printStackTrace();
}
```

&emsp;&emsp;这样可以获取一个RecordMetadata 对象，在RecordMetadata对象里包含了消息的一些元数据信息，比如当前消息的主题、分区号、分区中的偏移量、时间戳等。

&emsp;&emsp;KafkaProducer中一般会发生两种类型的异常: 可重试的异常和不可重试的异常。对于可重试的异常，如果配置了retries参数，那么只要在规定的重试次数内自行恢复了，就不会抛出异常。retries参数的默认值为0，配置方式参考如下:

```java
props.put(ProducerConfig.RETRIES_CONFIG,10);
```

&emsp;&emsp;示例中配置了10次重试。如果重试了10次之后还没有恢复，那么仍会抛出异常，进而发送的外层逻辑就要处理这些异常了。

&emsp;&emsp;对于异步发送的方式，一般是在send()方法里指定一个Callback的回调函数，Kafka在返回响应时调用该函数来实现异步的发送确认。虽然send()方法的返回值类型就是Future，本身就可以用作异步的逻辑处理。但是Future里的get()方法在何时调用，以及怎么调用都是需要面对的问题，消息不停地发送，那么诸多消息对应的Future对象的处理难免会引起代码处理逻辑混乱。使用Callback的方式非常简洁明了，Kafka有响应时就会回调，要么发送成功，要么抛出异常。异步发送方式的示例如下:

```java
producer.send(record,new Callback(){
  public void onCompletion(RecordMetadata metadata,Exception exception){
    if(exception != null){
      exception.printStackTrace();
    }else{
      System.out.println(metadata.topic()+"_"+metadata.partition()+":"+metadata.offset());
    }
  }
});
```

&emsp;&emsp;onCompletion()方法的两个参数是互斥的，消息发送成功时，metadata不为null而exception为null；消息发送异常时，metadata为null而exception不为null。

```java
producer.send(record1,callback1);
producer.send(record2,callback2);
```

&emsp;&emsp;对于同一个分区而言，如果消息record1于record2之前先发送，那么KafkaProducer就可以保证对应的callback1在callback2之前调用，也就是说，回调函数的调用也可以保证分区有序。

&emsp;&emsp;通常，一个KafkaProducer不会只负责发送单条消息，在发送完这些消息之后，需要调用KafkaProducer的close方法来回收资源。



```java
int i = 0;
while(i < 10){
  ProducerRecord<String,String> record = new ProducerRecord<>(topic,"msg"+i++);
  try{
    producer.send(record).get();
  }catch(InterruptedException | ExecutionException e){
    e.printStackTrace();
  }
}
producer.close();
```

&emsp;&emsp;close()方法会阻塞等待之前的所有的发送请求完成后再关闭KafkaProducer。与此同时，KafkaProducer还提供了一个带有超时时间的close()方法,具体定义如下:

```java
public void close(long timeout ,TimeUnit timeUnit);
```

### 1.3 序列化

&emsp;&emsp;生产者需要用序列化器(Serializer)把对象转换成字节数组才能通过网络发送给 Kafka。而在对侧，消费者需要用反序列器(Deserializer)把从 kafka 中收到的字节数组转换成相应对象。

&emsp;&emsp;客户端自带了org. apache.kafka. common. serialization. S tringSerializer用于序列化字符串，除此之外，还有ByteArray、ByteBuffer、Bytes、Double、Integer、Long这几种类型，它们都实现了org.apache.kafka.common.serialization. Serializer接口，此接口有3个方法: 

```java
public void configure(Map<String,?> configs,boolean isKey)
public byte[] serialize(String topic,T data)
public void close()
```

&emsp;&emsp;configure()方法用来配置当前类，serialize()方法用来执行序列化操作。而close()方法用来关闭当前序列器，一般情况下close()是一个空方法，如果实现了此方法，则必须确保此方法的幂等性，因为这个方法很可能会被KafkaProducer调用多次。

```java
public class StringSerializer implements Serializer<String>{
  private String encoding = ”UTF-8”;
  
  @Override 
  public void configure(Map<String ?> configs,boolean isKey) { 
  String propertyName ＝ isKey ? "key.serializer.encoding":"value.serializer.encoding"; 
  Object encodingValue = configs.get(propertyName); 
  if (encodingValue == null) {
    encodingValue = configs.get("serializer.encoding"); 
  }
  if(encodingValue != null && encodingValue instanceof String){
    encoding = (String) encodingValue;
  } 
    @Override 
    public byte[] serialize(String topic , String data ) { 
    try { 
      if (data == null ) {
        return nu11 ; 
      }else{
        return data.getBytes(encoding) ; 
      }
     } catch (UnsupportedEncodingException e) { 
       throw new SerializationException("Error when serializing" + "string to byte[] due to unsupported encoding"+ encoding );
    }
      @Override
      public void close(){
        
      }
}
```

&emsp;&emsp;首先是configure()方法，这个方法是在创建KafkaProducer实例的时候调用的，主要用来确定编码类型，不过一般客户端对于不过一般客户端对于 key.serializer.encoding, value.serializer.encoding和 serializer.encoding 这几个参数都不会配置,在KafkaProducer的参数集合(ProducerConfig)里也没有这个几个参数，所以一般情况下encoding的值就为默认的"UTF-8"。serialize()就是将String类型转为byte[]类型。

&emsp;&emsp;如果Kafka客户端提供的几种序列化器都无法满足应用需求，则可以通过JSON等序列化工具自定义实现。

&emsp;&emsp;假设要发送的消息都是Company对象，如下:

```java
import lombok.AllArgsConstructor; 
import lombok.Builder; 
import lombok.Data; 
import lombok.NoArgsConstructor; 
@Data 
@NoArgsConstructor 
@AllArgsConstructor 
@Builder 
public class Company { 
private String name ; 
private String address;
}
```

&emsp;&emsp;自定义的序列化器CompanySerializer

```java
public class CompanySerializer implements Serializer<Company>{
  @Override
  public void configure(Map configs,boolean isKey){}
  @Override
  public byte[] serialize(String topic,Company data){
    if(data == null){
      return null;
    }
    byte[] name,address;
    try{
      if(data.getName() != null){
        name = data.getName().getBytes("UTF-8");
      }else{
        name = new byte[0];
      }
      if(data.getAddress() != null){
        address = data.getAddress().getBytes("UTF-8");
      }else{
        address = new byte[0];
      }
      ByteBuffer buffer = ByteBuffer.allocate(4+4+name.length+address.length);
      buffer.putInt(name.length);
      buffer.putInt(name);
      buffer.putInt(address.length);
      buffer.putInt(address);
      return buffer.array();
    }catch(UnsupportedEncodingException e){
      e.pringStackTrace();
    }
    return new byte[0];
  }
  @Override
  public void close(){}
}
```

&emsp;&emsp;自定义序列化器使用示例

```java
Properties properties= new Properties() ; 
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName ));
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
CompanySerializer.class.getName()); 
properties.put("bootstrap.servers", brokerList); 
KafkaProducer<String , Company> producer = new KafkaProducer<> (properties) ; 
Company company = Company.builder().name("hiddenkafka").address.("China").build() ; 
ProducerRecord<String, Company> record = new ProducerRecord<>(topic , company) ; 
producer.send(record).get() ;
```



### 1.4 分区器

&emsp;&emsp;消息在通过 send()方法发往 broker 中， 有可能需要经过拦截器(Interceptor）、序列化器(serializer)和分区器(Partition)的一系列作用之后才能被真正地发 往broker 。消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。如果消息ProducerReord 中没有指定 partition 字段，那么就需要依赖分区器 ,根据 key这个字段来计算 partition 值。分区器的作用就是为消息分配分区。

&emsp;&emsp;Kafka 中提供 默认分区器是 org.apache.kafka.clients.producer.intemals.DefaultPartitioner,它实现了 org.apache. kafka .clients.producer.Partitioner 接口,这个接口中定义了2个方法，具体如下:

```java
public int partition(String topic , Object key , byte[] keyBytes,Object value , byte[] valueBytes, Cluster cluster) ; 
public void close() ;
```

&emsp;&emsp;其中 partition()方法用来计算分区号，返回值为 int 类型。 partition()方法中的参数分别表示主题、键、序列化后的键、值、序列 后的值，以及集群的元数据信息，通过这些信息可以实现功能丰富的分区器。close ()方法在关闭分区器的时候用来回收一些资源。

&emsp;&emsp;Partitioner 接口还有一 父接口 org.apache.kafka. common.Configurable ，这个接口中只有一个方法：

```java
void configure(Map<String ,?> configs);
```

&emsp;&emsp;Configurable 接口中的 configure （）方法主要 来获取配置信息及初始化数据。

&emsp;&emsp;在默认分区器 DefaultPartitioner 的实现中， close ()是空方法，而在 partition()方法中定义了主要的分区分配逻辑 。如果 key 不为 null ，那么默认的分区器会对 key 进行哈希（采MurmurHash2 算法，具备高运算性能及低碰撞率），最终根据得到 哈希值来 算分区号，有相同 key 的消息会被写入同一个分区 如果 key 为null ，那么消息将会以轮询的方式发往主题内的各个可用分区。

&emsp;&emsp;在不改变主题分区数量的情况下 key 与分区之间的映射可以保持不变。不过， 一旦主题中增加了分区，那么就难以保证 key 与分区之间的映射关系了。

&emsp;&emsp;除了使用 Kafka 提供的默认分区器进行分区分配，还可以使用自定义的分区器，只需同DefaultPartitioner 一样实 Partitioner 接口 即可。默认的分区器在 key为null 时不会选择非可用的分区，我们可以通过自 定义的分区器 DemoPartitioner 打破这一限制。

```java
public class DemoPartitioner implements Partitioner{
  private final AtomicInteger counter= new Atomiclnteger(O);
  
  @Override
  public int partition(String topic,Object key,byte[] keyBytes,Object value,byte[] valueBytes,Cluster cluster){
    List<Partitionlnfo> partitions= cluster.partitionsForTopic(topic) ;
    int numPartitions =partitions.size();
    if(null == keyBytes){
      return counter.getAndIncrement()% numPartitions;
    }else{
      return Utils.toPositive(Utils.murmur2(keyBytes)%numPartitions;
    }
                              
  }
  @Override
  public void close(){}
  @Override
  public void configure(Map<String,?> configs){}
}
```

&emsp;&emsp;实现自定义的DemoPartitioner类之后，需要通过配置参数partitioner.class来显式指定这个分区器。

```java
props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG ,DemoPartitioner.class.getName() ) ;
```



### 1.5 生产者拦截器

&emsp;&emsp;Kafka一共有两种拦截器(Kafka 0.10.0.0 以上): 生产者拦截器和消费者拦截器。生产者拦截器主要是自定义实现org.apache.kafka.clients.producer.Producerlnterceptor 接口。ProdeucerInterceptor接口中包含3个方法:

```java
public ProducerRecord<K,V> onSend(ProducerRecord<K,V> record);
public void onAcknowledgement(RecordMetadata medata,Exception exception);
public void close();
```

&emsp;&emsp;KafkaProducer 在将消息序列化和计算分区之前会调用生产者拦截器 onSend()方法来对消息进行相应的定制化操作。KafkaProducer 会在消息被应答(Acknowledgement )之前或消息发送失败时调用生产者拦截器的onAcknowledgement()方法，优先于用户设定的 Callback 之前执行。这个方法运行在Producer的 I/O 线程中，所以这个方法中实现的代码逻辑越简单越好 ,否则会影响消息的发送速度。close ()方法主要用于在关闭拦截器时执行一些资源的清理工作。在这 3个方法中抛出的异常都会被捕获并记录到日志中，但并不会再向上传递。

&emsp;生产者拦截器示例

```java
public class ProducerinterceptorPrefix implements Producerinterceptor<String, String>{ 
   private volatile long sendSuccess = 0; 
   private volatile long sendFailure = O; 
   @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String , String> record) { 
    String modifiedValue = "prefixl-" + record.value(); 
    return new ProducerRecord<>(record.topic(), record.partiti n(),record.timestamp() , record.key() , modifiedValue , record.headers()) ; 
     @Override
     public void onAcknowledgement( RecordMetadata recordMetadata, Exception e) { 
      if (e == null) { 
         sendSuccess++; 
       } else { 
         sendFailure ++; 
      }
     }
   @Override 
   public void close() { 
    double successRatio = (double)sendSuccess/(sendFailure + sendSuccess); 
System.out.println （"［ INFO ］发送成功率＝"
+ String.format ("%f" , successRatio * 100) ＋"号"）；
   }
@Override
public void configure(Map<String, ?>map) {}
```

&emsp;&emsp;实现自定义的 ProducerInterceptorPrefix 之后，需要在 KafkaProducer 的配置参数interceptor.classes 中指定这个拦截器，此参数的默认值为""。示例如下：

```java
properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG , ProducerinterceptorPrefix.class.getName());
```

&emsp;&emsp;KafkaProducer 中不仅可以指定一个拦截器，还可以指定多个拦截器以形成拦截链。拦截链会按照 interceptor.classes 参数配置的拦截器的顺序来一一执行（配置的时候，各个拦截器之间使用逗号隔开）。下面我们再添加一个自定义拦截器 ProducerlnterceptorPrefixPlus ，它只实现了 Interceptor 接口中的 onSend（）方法，主要用来为每条消息添加另一个前缀“prefix2 －”

```java
public ProducerRecord<String,String> onSend(ProducerRecord<String,String> record){
  String modifiedValue =”prefix2-”+record.value();
  return new ProducerRecord<> (record.topic(), record.partition() record.t mestamp () , record.key() , modifiedValue , record.headers ()) ;
}
```

```java
properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG , 
ProducerinterceptorPrefix.class.getName( + "," 
+ ProducerinterceptorPrefixPlus.class.getName ());
```



&emsp;&emsp;如果拦截链中的某个拦截器的执行需要依赖于前一个拦截器的输出，那么就有可能产生"副作用"。设想一下，如果前一个拦截器由于异常而执行失败，那么这个拦截器也就跟着无法继续执行。在拦截器中，如果某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。



## 二、原理分析

### 2.1 整体架构

![image](/Users/zhangquanwei/Downloads/生产者客户端架构.png)

&emsp;&emsp;整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程 (发送线程)。在主线程中由KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器(RecordAccumulator ，也称为消息收集器〉中。 Sender 线程负责从RecordAccumulator 获取消息并将其发送到 Kafka中。

&emsp;&emsp;RecordAccumulator主要用来缓存消息 以便Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。 RecordAccumulator 缓存的大 小可以通过生产者客户端参数buffer.memory 配置，默认值为 33554432B ，即 32MB,如果生产者发送消息的速度超过发送到服务器的速度 ，则会导致生产者空间不足，这个时候KafkaProducer的send（） 方法调用要么被阻塞，要么抛出异常，这个取决于参数 max.block.ms 的配置，此参数的默认值为60000,即60秒。

&emsp;&emsp;主线程中发送过来的消息都会被追加加到 RecordAccumulator 的某个双端队列(Deque)中，在RecordAccumulator 的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch ，即 Deque <ProducerBatch＞。消息写入缓存时，追加到双端队列的尾部： Sender读取消息时 ，从双端队列的头部读取。注意ProducerBatch 不是 ProducerRecord, ProducerBatch 中可以包含一至多个 ProducerRecord 。通俗地说， ProducerRecord 是生产者中创建的消息，而Producer Batch 是指一个消息批次 ProducerRecord 会被包含在 ProducerBatch 中，这样可以使节的使用更加紧凑。与此同时，将较小的 ProducerRecord 凑成一个较大 ProducerBatch ，也可以减少网络请求的次数以提升整体的吞吐量 。如果生产者客户端需要向很多分区发送消息， 则可以buffer.memory 参数适当调大以增加整体的吞吐量。

&emsp;&emsp;消息在网络上都是以字节(Byte)的形式传输的，在发送之前需要创建 块内存区域来保存对应的消息 。在 Kafka 生产者客户端中，通过 java.io.ByteBuffer 实现消息内存的创建和释放。不过频繁的创建和释放是比较耗费资源的，在 RecordAccumulator 的内部还有一个 BufferPool,它主要用来实现 ByteBuffer 的复用，以实现缓存的高效利用 。不 BufferPool 只针对特定大小的ByteBuffer 进行管理，而其他大小的 ByteBuffer 不会缓存进 BufferPool 中，这个特定的大小batch.size 参数来指定，默认值为 16384B ，即 16KB 我们可以适当地调大 batch.size参数以便多缓存一些消息。

&emsp;&emsp;ProducerBatch 大小和 batch size 参数也有着密切的关系。当一条消息(ProducerRecord)流入 RecordAccumulator 时，会先寻找与消息分区所对应的双端队列(如果没有则新建)，再从这个双端队列的尾部获取一个 ProducerBatch （如果没有则新建），查看 ProducerBatch 中是否还可以写入这个 ProducerRecord ，如 果可以 写入，如果不可以则 需要 建一个新Producer Batch 。在新建 ProducerBatch 评估这条消息的大小是否超过 batch size 参数的大小，如果不超过，那么就以 batch size 参数的大 来创建 ProducerBatch ，这样在使用完这段内存区域之后，可以通过 BufferPool 的管理来进行 用；如果超过，那么就以评估的大小来ProducerBatch 这段内存区域不会被复用。

&emsp;&emsp;Sender从RecordAccumulator 获取缓存的消息之后，会进一步将原本<分区， Deque\<Producer Batch>>的保存形式转变成<Node List< ProducerBatch>的形式，其中 Node 表示 Kafka集群 broker 节点 。对于网络连接来说，生产者客户端是与具体的broker 节点建立的连接，也就是向具体的 broker 节点发送消息，而并不关心消息属于哪一个分区；而对于 KafkaProducer的应用逻辑而言，我们只关注向哪个分区中发送哪些消息，所以在这里需要做一个应用逻辑层面到网络 1/0 层面的转换。

&emsp;&emsp;在转换成<Node, List\<ProducerBatch>>的形式之后， Sender 会进一步封装成<Node,Request> 的形式，这样就可以将 Request 请求发往各个 Node了,这里Request是指Kafka各种协议请求，对于消息发送而言就是指具体的 ProduceRequest 。

&emsp;&emsp;请求在从Sender 线程发往 Kafka 之前还会保存到 InFlightRequests 中,InFlightRequests保存对象的具体形式为Map\<NodeId,Deque\<Request>>,它的主要作用是缓存 了已经发出去但还没有收到响应的请求(Nodeld 是一个 String 类型，表示节点的 id 编号）。与此同时，InFlightRequests 还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接（也就是客户端与 Node 之间的连接）最多缓存的请求数。这个配置参数为 max.inflight.requests.per. connection ，默认值为5 ，即每个连接最多只能缓存 5个未响应的请求，超过该数值之后就不能再向这个连接发送更多的请求了，除非有缓存的请求收到了响应（ Response ）。通过比较 Deque\<Request>的size 与这个参数的大小来判断对应的 Node 中是否己经堆积了很多未响应的消息，如果真是如此，那么说明这个 Node 节点负载较大或网络连接有问题，再继续向其发送请求会增大请求超时的可能。

### 2.2 元数据的更新

&emsp;&emsp;从InFlightRequests还可以获得leastLoadedNode,即所有Node中负载最小的那一个。这里的负载最小是通过每个 Node在InFlightRequests 中还未确认的请求决定的，未确认的请求越多则认为负载越大。

![image](/Users/zhangquanwei/Downloads/leastLoadeNode.png)

&emsp;&emsp;图中展示了 三个节点Node0, Node1, Node2 ，很明显 Nodel1负载最小也就是说， Node1为当前的 leastLoadedNode。选择 leastLoadedNode 发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。 leastLoadedNode 的概念可以用于多个应用场合，比如元数据请求、消费者组播协议的交互。

&emsp;&emsp;使用如下的方式创建了一条消息ProducerRecord:

```java
ProducerRecord<String,String> record = new ProducerRecord<>(topic,"Hello,Kafka!");
```

&emsp;&emsp;我们只知道主题的名称，对于其他一些必要的信息却一无所知 KafkaProducer 要将此消息追加到指定主题的某个分区所对应的 leader 副本之前，首先需要知道主题的分区数量，然后经过计算得出（或者直接指定〉目标分区，之后 KafkaProducer 需要知道目标分区的 leade 副本所在的 broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka ，在这一过程中 需要的信息都属于元数据信息。

&emsp;&emsp;元数据是指 Kafka 集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的 lead 副本分配在哪个节点上， follower 副本分配在哪些节点上，哪些副本在 AR 、ISR 等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。

&emsp;&emsp;当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过metadata.max.age.ms 时间没有更新元数据都会引起元数据的更新操作 。客户端参数metadata.max.age.ms 的默认值为 300000 ，即5分钟。元数据的更新操作是在客户端 内部进行的，对客户端的外部使用者不可见。当需要更新元数据时，会先挑选出leastLoadedNode, 然后向这个Node 发送 MetadataRequest 请求来获取具体的元数据信息。这个更新操作是由 Sender线程发起的，创建完MetadataRequest 之后同样会存入 InFlightRequests ，之后的步骤就和发送消息时的类似 元数据虽然由 Sender 线程负责更新，但是主线程也需要读取这些信息，这里的数据同步通过 synchronized 和final关键字来保障。

## 三、重要的生产者参数

#### 1.acks

&emsp;&emsp;这个参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。 acks 是生产者客户端中一个非常重要的参数 ，它涉及消息的可 性和吞吐量之间的权衡acks 参数有3种类型的值（都是字符串类型）。

- acks = 1。默认值即为 1。生产者发送消息之后，只要分区的leader 副本成功写入消

  息，那么它就会收到来自服务端的成功响应。如果消息无法写入 leader 副本，比如在leader 副本崩溃、重新选举新的 leader 副本的过程中，那么生产者就会收到一个错误的响应，为了避免消息丢失，生产者可以选择重发消息 。如果消息写入 le ader 副本并返回成功响应给生产者，且在被其他 fo llo wer 副本拉取之前 leader 副本崩溃，那么此时消息还是会丢失，因为新选举的 leader 副本中并没有这条对应的消息 acks 设置为1，是消息可靠性和吞吐量之间的折中方案。

- acks = 0。生产者发送消 息之后不需要等待任何服务端的响应。如果在消息从发送到写入 Kafka 的过程中出现某些异常，导致 Kafka 并没有收到这条消息，那么生产者也无从得知，消息也就丢失了。在其他配置环境相同的情况下， acks 设置为 0可以达到最大的吞吐量。

- acks=-1或acks=all。生产者在消 息发送之后，需要等待 ISR 中的所有副本都成功

  写入消息之后才能够收到来自服务端的成功响应。在其他配置环境相同的情况下，

  acks 设置为 (all)可以达到最强的可靠性。但这并不意味着消息就一定可靠，因

  ISR 中可能只有 leader 副本，这样就退化成了 acks= 1的情况。要获得更高的消息

  可靠性需要配合 min.insync.replicas等参数的联动

#### 2.max.request.size

&emsp;&emsp;这个参数用来限制生产者客户端能发送的消息的最大值，默认值为 1048576B ，即 1MB一般情况下，这个默认值就可以满足大多数的应用场景了。不建议盲目地增大这个参数的配置值，尤其是在对 Kafka 整体脉络没有足够把控的时候。因为这个参数还涉及一些其参数的联动，比如 broker 端的 message.max.bytes 参数，如果配置错误可能会引起一些不必要的异常 比如将 broker 端的 message.max.bytes 参数配置为 10 ，而 max.request.size参数配置为 那么当我 发送一条大小为 15B 的消息时，生产者客户端就会报出如下的异常:

```
org apache kafka.commo errors.RecordTooLargeExcept on The request included a message larger than the max message size the server will accept .
```

#### 3.retries 和retry.backoff.ms

&emsp;&emsp;retries 参数用来配置生产者重试的次数，默认值为 0，即在发生异常的时候不进行任何重试动作。消息在从生产者发出到成功写入服务器之前可能发生一些临时性的异常， 比如网抖动、 leader 副本的选举等，这种异常往往是可以自行恢复的，生产者可以通过配置 retries大于 0的值，以此通过内部重试来恢复而不是一昧地将异常抛给生产者的应用程序。如 果重试达到设定的次数，那么生产者就会放弃重试并返回异常。不过并不是所有的异常都是可以通过重试来解决的，比如消息太大，超过 max.request.size 参数配置的值时，这种方式就不可行了.

&emsp;&emsp;重试还和另一个参数 retry.backoff.ms 有关，这个参数的默认值为 100 ,它用来设定

两次重试之间的时间间隔，避免无效的频繁重试。在配置 retries和 retry.backoff.ms

之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试

&emsp;&emsp;Kafka 可以保证同一个分区中的消息是有序的。如果生产者按照一定的顺序发送消息，那么这些消息也会顺序地写入分区，进而消费者也可以按照同样的顺序消费它们。对于某些应用来说，顺序性非常重要 ，比如 MySQL binlog 输，如果出现错误就会造成非常严重的后果果将 acks 参数配置为非零值，并且 max .flight.requests.per.connection 参数配置为大于 1的值，那么就会出现错序的现象 如果第一批次消息写入失败 而第二批次消息写入成功，那么生产者会重试发送第一批次的消息， 此时如果第一 次的消息写入成功，那么这两个批次的消息就出现了错序 。一般而言，在需要保证消息顺序的场合建议把参数max.in.flight.requests.per.connection 配置为 1，而不是把 acks 配置为0,不过这样也会影响整体的吞吐。

#### 4.compression.type

&emsp;&emsp;这个参数用来指定消息的压缩方式，默认值为“none ”，即默认情况下，消息不会被压缩。该参数还可以配置为"gzip ","snappy" 和"z4" 对消息进行压缩可以极大地减少网络传输、降低网络I/O，从而提高整体的性能 。消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩

#### 5.connections.max.idle.ms

&emsp;&emsp;这个参数用来指定在多久之后关闭限制的连接，默认值是 540000 ms ，即9分钟。

#### 6.linger.ms

&emsp;&emsp;这个参数用来指定生产者发送 ProducerBatch 之前等待更多消息(ProducerRecord)加入ProducerBatch 时间，默认值为 0。生产者客户端会在 ProducerBatch 填满或等待时间超过linger.ms 值时发送出去。增大这个参数的值会增加消息的延迟，但是同时能提升一定的吞吐量。 

#### 7.receive.buffer.bytes

&emsp;&emsp;这个参数用来设置 Socket 接收消息缓冲区(SO_RECBUF)的大小，默认值为 32768 B，即32KB。如果设置为 -1，则使用操作系统的默认值。如果 Producer与 Kafka 于不同的机房则可以适地调大这个参数值

#### 8.send.buffer.bytes

&emsp;&emsp;这个参数用来设置 Socket 发送消息缓冲区(SO_RECBUF)的大小，默认值为131072B，即128KB。如果设置为 -1，则使用操作系统的默认值。

#### 9.request.timeout.ms

&emsp;&emsp;这个参数用来配置 Producer 等待请求响应的最长时间，默认值为 30000 ms 。请求超时之后可以选择进行重试。注意这个参数需要 broker 端参数 replica.lag.time.max ms值要大，这样可以减少因客户端重试而引起的消息重复的概率。